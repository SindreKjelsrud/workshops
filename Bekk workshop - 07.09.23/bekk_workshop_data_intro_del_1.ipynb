{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Workshop: Introduksjon til dataflyt og transformasjon**\n",
        "\n",
        "**Du vil lÃ¦re:**\n",
        "- Helt overordnet hva dataflyt og transformasjoner er, hva det innebÃ¦rer og hvordan det utfÃ¸res i praksis\n",
        "- Litt om Google Cloud Storage og Google BigQuery\n",
        "- Ã… laste inn, hente ut og jobbe med data fra Google BigQuery\n",
        "- GjÃ¸re enkle transformasjoner ved hjelp av datamanipuleringsverktÃ¸y\n",
        "- Lage et nytt og rikere datasett med data fra flere kilder\n",
        "\n",
        "ðŸ’¡ Oppgave 1-4 er utforskende i GCP og kan timeboxes til ca. 10 minutter."
      ],
      "metadata": {
        "id": "raflZ3eh1f4w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# **Relevante GCP-komponenter for workshopen**\n",
        "## Google Cloud Storage\n",
        "\n",
        "Google Cloud Storage (GCS) er et filomrÃ¥de hvor vi kan lagre filer pÃ¥ ulike formater, med bÃ¥de strukturerte og ustrukturerte data. GCS er et fint landingspunkt for data, slik at du kan jobbe uavhengig av systemene dataene stammer fra (f.eks eksterne API-er).\n",
        "\n",
        "Vi bruker ofte begrepet \"storage bucket\" for en logisk oppdeling av et filomrÃ¥de, tilsvarende som en filmappe pÃ¥ din maskin.\n",
        "\n",
        "Data i en storage bucket er som regel ikke klargjort for analyseformÃ¥l. Vi Ã¸nsker derfor Ã¥ prosessere og flytte den til et annet verktÃ¸y. Et slikt verktÃ¸y kan vÃ¦re Google BigQuery, som er en database tilpasset analyse. Dette kan videre kobles opp mot visualiserings- og modelleringsverktÃ¸y som Colab-notebooks.\n",
        "\n",
        "## Google BigQuery\n",
        "\n",
        "BigQuery er en SQL-basert database som er optimalisert for analyse. I motsetning til tradisjonelle SQL-databaser er BigQuery kolonnebasert istedenfor radbasert. Dette gjÃ¸r den optimalisert til Ã¥ regne ut aggregerte tall. BigQuery takler tabeller med et hÃ¸yt antall kolonner svÃ¦rt godt."
      ],
      "metadata": {
        "id": "DPfwNsUoPddk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# **Bolk 1: Bli kjent med datasettene**\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "wQ3gSFzt9Dnz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Oppgave 1: Bli kjent med Google Cloud Storage** â˜ï¸\n",
        "\n",
        "GÃ¥ til [Google Cloud Console](https://console.cloud.google.com), logg inn med e-posten din og velg prosjekt \"data-intro\" oppe i venstre hjÃ¸rne.\n",
        "\n",
        "I Google Cloud Console (GUI) for prosjektet (data-intro), finn Google Cloud Storage. Du kan enten finne GCS via menyen eller sÃ¸ke etter den i sÃ¸kefeltet.\n",
        "\n",
        "I prosjektet finner du en bucket med to ulike datasett. Vi skal inspisere metadataen til disse filene.\n",
        "\n",
        "a) Hvilken filtype er de?\n",
        "  \n",
        "  \n",
        "b) Hvor store er filene?\n",
        "  "
      ],
      "metadata": {
        "id": "ydTsudgDBZMF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO\n",
        "# Svar a: csv\n",
        "# Svar b: 1GB"
      ],
      "metadata": {
        "id": "jTiSwTo9_ffb"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Oppgave 2: Importer dataen til BigQuery** ðŸ”\n",
        "\n",
        "For Ã¥ se nÃ¦rmere pÃ¥ innholdet i datasettene Ã¸nsker vi Ã¥ flytte de til BigQuery. GjÃ¸r fÃ¸lgende i [Google Cloud Console](https://console.cloud.google.com):\n",
        "\n",
        "1. Finn BigQuery i menyen\n",
        "2. Velg BigQuery-prosjektet \"Data intro\" og deretter marker datasettet bysykkel_main\n",
        "3. I menylinjen oppe til hÃ¸yre, velg \"Create table\".\n",
        "4. Under \"Source\" kan du velge datakilden din. Vi Ã¸nsker Ã¥ velge bysykkeldatasettet fra Storage Bucket. Filformatet fant du i oppgave 1.\n",
        "5. Under \"Destination\" kan du kalle den nye tabellen din `bysykkel_(gruppenavn)`.\n",
        "6. La BigQuery definere skjema for deg, og behold ellers standard-innstillingene.\n",
        "7. Trykk pÃ¥ \"Create Table\"\n",
        "\n",
        "NÃ¥ starter en jobb med Ã¥ laste inn datasettet fra GCS til BigQuery og vil ta ca. 30 sekunder."
      ],
      "metadata": {
        "id": "9tCc63aZWUgl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Oppgave 3: Bli kjent med bysykkel-datasettet** ðŸš²\n",
        "\n",
        "NÃ¥r vi markerer tabellen i BigQuery som vi laget i forrige oppgave ser vi en rekke metadata, samt en preview-funksjon for Ã¥ undersÃ¸ke radene i datasettet vÃ¥rt.\n",
        "\n",
        "Hva finner du ut om skjema (datatypene) og innholdet?"
      ],
      "metadata": {
        "id": "be4ImxshDMwB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "## **Oppgave 4: Bli kjent med vÃ¦rdatasettet** ðŸŒ¦\n",
        "Vi har allerede lastet inn vÃ¦rdatasettet inn i BigQuery (`vÃ¦rdata_oslo`).\n",
        "\n",
        "Hva finner du ut om skjema (datatypene) og innholdet for dette datasettet?\n",
        "\n"
      ],
      "metadata": {
        "id": "cI5dylecWZnY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Bolk 2: Vasking av data**\n",
        "\n",
        "NÃ¥ som vi har flyttet datasettene til et passende sted og blitt litt kjent med tabellenes skjema skal vi prÃ¸ve Ã¥ slÃ¥ disse sammen!"
      ],
      "metadata": {
        "id": "82bhxJ1T8O4S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Autentisering**\n",
        "\n",
        "Det fÃ¸rste vi mÃ¥ gjÃ¸re er Ã¥ autentisere Colab-notebooken mot BigQuery. Koden under vil generere et popup-vindu der du mÃ¥ godkjenne dette.\n",
        "\n"
      ],
      "metadata": {
        "id": "s9nSGug2NrRS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Authenticate your Google Account\n",
        "# Doing so means you have access to various\n",
        "# resources connected to your account, such\n",
        "# as BigQuery tables, Storage buckets etc.\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "metadata": {
        "id": "eqEVQIJsT7K1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**BigQuery-klienten**\n",
        "\n",
        "NÃ¥ som vi er autentisert, kan vi bruke BigQuery-biblioteket. Kodesnutten under kobler oss til BigQuery-klienten og tar samtidig i bruk `magics`-operatoren som simpelthen lar oss hente data fra en tabell.\n",
        "\n",
        "KjÃ¸r kodesnutten under.\n"
      ],
      "metadata": {
        "id": "CSvHGiNTegzl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext google.cloud.bigquery\n",
        "from google.cloud.bigquery import magics\n",
        "magics.context.project = 'data-intro'"
      ],
      "metadata": {
        "id": "oQfp_SWHqeP7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Pandas DataFrames**\n",
        "\n",
        "Operatoren over skriver resultatet fra BigQuery ut som en _DataFrame_ fra Pandas-biblioteket. DataFrames er svÃ¦rt nyttige nÃ¥r vi jobber med tabulÃ¦r data, bÃ¥de for datautforskning og -manipulasjon.\n",
        "\n",
        "Vi kaller dataframesene hhv. `df_bysykkel` og `df_weather`. KjÃ¸r kodeblokkene under (husk Ã¥ bytte tabell-referanse):"
      ],
      "metadata": {
        "id": "jyJPs0v4T-35"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%bigquery df_bysykkel\n",
        "SELECT * FROM `data-intro.bysykkel_main.bysykkel_august` # Bytt ut med ditt eget tabell-navn\n"
      ],
      "metadata": {
        "id": "N7z9qGJUqvf5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%bigquery df_weather\n",
        "SELECT * FROM `data-intro.bysykkel_main.vÃ¦rdata_oslo`"
      ],
      "metadata": {
        "id": "jtVUYufOrPge"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Oppgave 5: Lage et utvidet datasett** ðŸ‘©ðŸ»â€ðŸ’»\n",
        "Vi Ã¸nsker Ã¥ slÃ¥ sammen de to datasettene slik at vi kan gjÃ¸re analyse pÃ¥ tvers av disse. FÃ¸r vi gjÃ¸r det mÃ¥ vi finne en felles kolonne for begge datasett.\n",
        "\n",
        "PÃ¥ en DataFrame-instans, `df`, har vi en rekke nyttige metode og felter, f.eks:\n",
        "\n",
        "```python\n",
        "df.shape                  # Dimensjon\n",
        "df.info()                 # Oppsummering av stÃ¸rrelse og innhold\n",
        "df.describe()             # Grunnleggende statistiske egenskaper\n",
        "df.head()                 # Lister de fÃ¸rste radene i datasettet\n",
        "df.tail()                 # Lister de siste radene i datasettet\n",
        "df[\"kolonnenavn\"]         # Aksessering av spesifikk kolonne\n",
        "df[\"kolonnenavn\"].iloc[n] # Aksessere rad n i spesifikk kolonne\n",
        "```"
      ],
      "metadata": {
        "id": "AsShu4MB8Ifr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vi mÃ¥ finne en kolonne med fellesdata for Ã¥ kunne slÃ¥ sammen tabellene. Bruk en (eller flere) av metodene over for Ã¥ inspisere innholdet i de to tabellene.  \n",
        "\n",
        "SÃ¥ du noen fellesnevnere da du undersÃ¸kte innholdet i tabellene?"
      ],
      "metadata": {
        "id": "ayDXtr1wJJfv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DITT SVAR HER\n",
        "df_bysykkel['started_at']\n",
        "df_weather['date']"
      ],
      "metadata": {
        "id": "CcnsieJ1Jq0k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Uten Ã¥ rÃ¸pe for mye er det flere gode kolonne-kandidater i `df_bysykkel` som kan brukes pÃ¥ Ã©n kolonne i `df_weather`. Likevel er det ikke mulig Ã¥ bruke noen av de rett ut av boksen. Klarer du se hvorfor?\n"
      ],
      "metadata": {
        "id": "Q_TKKnykJtzg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DITT SVAR HER\n",
        "# Ulikt format pÃ¥ dato, df_bysykkel er df_weather"
      ],
      "metadata": {
        "id": "I_QBUIIN7vux"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Oppgave 6: Rydde opp i datasettene** ðŸ§¹\n",
        "Transformasjoner er en stor og viktig prosess nÃ¥r vi jobber med data. Ofte er datasettene vi har til rÃ¥dighet ikke pÃ¥ det formatet vi Ã¸nsker Ã¥ ha de pÃ¥. Ã… transformere data betyr Ã¥ gjÃ¸re endringer, for eksempel:\n",
        "\n",
        "- slÃ¥ sammen datasett\n",
        "- endre pÃ¥ datatyper\n",
        "- fjerne duplikater\n",
        "- gjÃ¸re utregninger med basis i andre kolonner\n",
        "- fjerne potensielle \"outliers\" som kan Ã¸delegge grunnlaget vÃ¥rt for analyse\n",
        "\n",
        "> Prosessen over kalles ofte for Ã¥ \"vaske\" data ðŸ§¼\n",
        "\n",
        "Vi mÃ¥ fÃ¥ dato-kolonnene til Ã¥ vÃ¦re pÃ¥ samme format. En mÃ¥te vi kan gjÃ¸re dette pÃ¥ er Ã¥ fjerne klokkeslettet og kun bruke dato-delen av `started_at`. Ulempen med dette er at vi da mister informasjon vi kanskje Ã¸nsker Ã¥ bruke videre i analysedelen.\n",
        "\n",
        "Vi lÃ¸ser dette problemet med Ã¥ lage en hjelpekolonne, altsÃ¥ en ny midlertidg kolonne som kun brukes nÃ¥r vi slÃ¥r sammen datasettene\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "wJB6gAMbwtfw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Oppgave 6.1**\n",
        "\n",
        "Lag en ny kolonne i `df_bysykkel`, `trip_date`, som kun inneholder datoen fra kolonnen `started_at`. Det kan ta litt tid Ã¥ oppdatere de 5.7 millioner radene vi har i tabellen.\n",
        "\n",
        "> **Hint**: Pandas har en funksjon [`to_datetime`](https://pandas.pydata.org/docs/reference/api/pandas.to_datetime.html) som lar deg tilpasse tidspunkter, samt en funksjon [`dt.strftime`](https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.strftime.html) som lar deg formatere dato til et Ã¸nsket format ðŸ¼"
      ],
      "metadata": {
        "id": "aGGRSWyCBUtD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "# DIN KODE HER\n",
        "df_bysykkel['trip_date'] = pd.to_datetime(df_bysykkel['started_at']).dt.strftime['%Y-%m-%d']\n",
        "df_bysykkel.head()\n",
        "print(df_bysykkel.head())"
      ],
      "metadata": {
        "id": "8YSrupR_w0x3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title LÃ¸sningsforslag\n",
        "import pandas as pd\n",
        "df_bysykkel[\"trip_date\"] = pd.to_datetime(df_bysykkel[\"started_at\"]).dt.strftime(\"%Y-%m-%d\")\n",
        "df_bysykkel.head()"
      ],
      "metadata": {
        "id": "nS7wQ0nz9qnW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Oppgave 6.2**\n",
        "ForsÃ¸k Ã¥ slÃ¥ sammen de to datasettene med hjelpekolonnen `trip_date` ved Ã¥ bruke Pandas' [merge](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.merge.html)-funksjon. Fungerer det Ã¥ slÃ¥ sammen nÃ¥? Hvordan ser datasettet ut?\n",
        "\n",
        "> **Hint:** Du kan sjekke hvilke datatyper dataframen din inneholder ved Ã¥ bruke Pandas sitt `dtypes`-attributt, f.eks `df_bysykkel.dtypes`"
      ],
      "metadata": {
        "id": "fnxmSPiGN4b9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DIN KODE HER\n",
        "df_merged = df_bysykkel.merge(df_weather, how='outer', left_on='trip_date', right_on='date')"
      ],
      "metadata": {
        "id": "O1AaLoZ9NzjD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "outputId": "d48af1ee-6e1a-401f-a701-498cf41d780a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-8a12da829080>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# DIN KODE HER\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf_merged\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_bysykkel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_merged\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df_bysykkel' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title LÃ¸sningsforslag\n",
        "\"\"\"\n",
        "Det vil i prinsippet fungere, men det er likevel ikke riktig fordi kolonnene har\n",
        "ulike datatyper - started_at er av typen datetime64 og trip_date er av typen object\n",
        "\"\"\""
      ],
      "metadata": {
        "cellView": "form",
        "id": "yuGEPmx2opXQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "a77dee3c-252b-4cf3-8c9c-5f41833f0593"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nDet vil i prinsippet fungere, men det er likevel ikke riktig fordi kolonnene har\\nulike datatyper - started_at er av typen datetime64 og trip_date er av typen object\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Oppgave 6.3**\n",
        "GjÃ¸r nÃ¸dvendige endringer i kolonnen `trip_date` i bysykkeldatasettet og `date` i vÃ¦rdatasettet for Ã¥ kunne slÃ¥ sammen.\n"
      ],
      "metadata": {
        "id": "E-QdbA1COWN_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DIN KODE HER\n",
        "import pandas as pd\n",
        "\n",
        "df_bysykkel['trip_date'] = pd.to_datetime(df_bysykkel['trip_date'])\n",
        "df_weather['date'] = pd.to_datetime(weather['date'])"
      ],
      "metadata": {
        "id": "lR-0dx0cxB6_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title LÃ¸sningsforslag\n",
        "\n",
        "# Vi setter begge kolonnen til Ã¥ vÃ¦re av type datetime (datotid).\n",
        "\n",
        "df_bysykkel[\"trip_date\"] = pd.to_datetime(df_bysykkel[\"trip_date\"])\n",
        "df_weather[\"date\"] = pd.to_datetime(df_weather[\"date\"])"
      ],
      "metadata": {
        "id": "wUGlrEsUu8uM",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Oppgave 6.4**\n",
        "NÃ¥ skal det fungere Ã¥ slÃ¥ sammen datasettene! ðŸŽ‰ Vi Ã¸nsker Ã¥ supplere hver rad av bysykkeldatasettet med vÃ¦rdata fra den aktuelle dagen. Skriv kode under som oppnÃ¥r dette.\n",
        "\n",
        "> ðŸ’¡ RekkefÃ¸lgen og type join (left, right, outer etc.) har noe Ã¥ si nÃ¥r datasettene slÃ¥s sammen. Tommelfingerregelen er at man alltid skal starte med den stÃ¸rste tabellen ved en merge av ytelsesgrunner. Forskjellen pÃ¥ type joins kan man lese mer om [her](https://stackoverflow.com/questions/5706437/whats-the-difference-between-inner-join-left-join-right-join-and-full-join).\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "vy9wVOCGyB_-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DIN KODE HER\n"
      ],
      "metadata": {
        "id": "30ZZiRcWyGdK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title LÃ¸sningsforslag\n",
        "df_merged = df_bysykkel.merge(df_weather, left_on=\"trip_date\", right_on=\"date\", how=\"left\")\n",
        "df_merged.head()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "XFT0gIqkv9ej"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Oppgave 6.5**\n",
        "Om vi sjekker typene til kolonnene med vÃ¦rdata (ved bruk av `df_merged.dtypes` igjen) ser vi at verdiene i disse kolonnene er strenger. Det gjÃ¸r det ikke mulig for oss Ã¥ aggregere verdiene, sÃ¥ vi er nÃ¸dt til Ã¥ fÃ¥ de over pÃ¥ tallformat.\n",
        "\n",
        "Kodesnutten under forsÃ¸ker Ã¥ gjÃ¸re om verdiene pÃ¥ temperatur og nedbÃ¸rsmengde til typen `float`. Hvorfor fungerer det ikke Ã¥ gjÃ¸re om kolonnen direkte?"
      ],
      "metadata": {
        "id": "vPrY9Nj9yLdm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_merged[\"mean_temperature\"] = df_merged[\"mean_temperature\"].astype('float')\n",
        "df_merged[\"precipitation_amount\"] = df_merged[\"precipitation_amount\"].astype('float')"
      ],
      "metadata": {
        "id": "Y6lQfo3LUYn0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title LÃ¸sningsforslag\n",
        "\"\"\"\n",
        "Kolonnen ser tilsynelatende ut til Ã¥ kun bestÃ¥ av tall. Hvis vi derimot inspiserer\n",
        "verdiene nÃ¦rmere, ser vi at noen ganger forekommer strengen \"NULL\" som ikke er et tall.\n",
        "Pandas fÃ¥r derfor ikke til Ã¥ gjÃ¸re om datatypen fÃ¸r vi gjÃ¸r noe med dette.\n",
        "\"\"\""
      ],
      "metadata": {
        "cellView": "form",
        "id": "XS7ylVVnzD0h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Oppgave 6.6**\n",
        "Endre datatypen pÃ¥ nedbÃ¸rskolonnen og temperaturkolonnen slik at det blir desimaltall.\n",
        "\n",
        "> **Hint**: Vi er nÃ¸dt til Ã¥ fjerne `NULL`-verdiene vi oppdaget i forrige oppgave. Bruk `replace`-funksjonen til dette ved Ã¥ sette en tom verdi, som i Python-verdenen heter `None`. Kan du tenke deg hvorfor vi bruker en tom verdi istedenfor eksempelvis 0 her?"
      ],
      "metadata": {
        "id": "4sbgPwHLZgvJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DIN KODE HER"
      ],
      "metadata": {
        "id": "m0GmJP7GYv9b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title LÃ¸sningsforslag\n",
        "df_merged[\"mean_temperature\"] = df_merged[\"mean_temperature\"].replace({'NULL': None}).astype('float')\n",
        "df_merged[\"precipitation_amount\"] = df_merged[\"precipitation_amount\"].replace({'NULL': None}).astype('float')\n",
        "\n",
        "\"\"\"\n",
        "Vi kunne teknisk sett gjort om NULL til 0, men dette ville fÃ¥tt betydning for\n",
        "statistiske verdier som gjennomsnitt og lignende. Hvordan man hÃ¥ndterer NULL-verdier\n",
        "avhenger av bruksomrÃ¥det og krever ofte dypere forstÃ¥else av domenet man jobber med.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "JDrCEgmS0wef",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Oppgave 6.7**\n",
        "\n",
        "Rydd opp ved Ã¥ fjerne hjelpekolonnen fra `df_merged`\n",
        "\n",
        "> **Hint**: `drop`-funksjonen kan komme godt med her ðŸ—‘\n"
      ],
      "metadata": {
        "id": "sk8NH-K9Uo6-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DIN KODE HER"
      ],
      "metadata": {
        "id": "GpdDnOQoyPbq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title LÃ¸sningsforslag\n",
        "df_merged = df_merged.drop(columns=\"trip_date\")\n",
        "df_merged.head()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "g_bJiQPB10vb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Vi har nÃ¥ et utvidet datasett! ðŸŽ‰ðŸ¥‚ðŸŽŠ\n",
        "\n",
        "\n",
        "Vanligvis ville vi ha skrevet datasettet tilbake til BigQuery, men det gjÃ¸r vi ikke i denne workshopen (det tar lang tid, vi har mye dataðŸ˜´)\n",
        "\n",
        "Pandas har en ganske snedig funksjon som kan gjÃ¸re dette!\n",
        "\n",
        "```df_merged.to_gbq(\"bysykkel_main.bysykkel_med_vÃ¦rdata\", project_id=\"data-intro\")```\n",
        "\n",
        "NÃ¥r vi skriver til BigQuery, vil datatypene i dataframen fÃ¸lge med og sette riktig skjema i BigQuery\n"
      ],
      "metadata": {
        "id": "vUZMf3ycUY7D"
      }
    }
  ]
}