{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Workshop: Introduksjon til dataflyt og transformasjon**\n",
        "\n",
        "**Du vil l√¶re:**\n",
        "- Helt overordnet hva dataflyt og transformasjoner er, hva det inneb√¶rer og hvordan det utf√∏res i praksis\n",
        "- Litt om Google Cloud Storage og Google BigQuery\n",
        "- √Ö laste inn, hente ut og jobbe med data fra Google BigQuery\n",
        "- Gj√∏re enkle transformasjoner ved hjelp av datamanipuleringsverkt√∏y\n",
        "- Lage et nytt og rikere datasett med data fra flere kilder\n",
        "\n",
        "üí° Oppgave 1-4 er utforskende i GCP og kan timeboxes til ca. 10 minutter."
      ],
      "metadata": {
        "id": "raflZ3eh1f4w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# **Relevante GCP-komponenter for workshopen**\n",
        "## Google Cloud Storage\n",
        "\n",
        "Google Cloud Storage (GCS) er et filomr√•de hvor vi kan lagre filer p√• ulike formater, med b√•de strukturerte og ustrukturerte data. GCS er et fint landingspunkt for data, slik at du kan jobbe uavhengig av systemene dataene stammer fra (f.eks eksterne API-er).\n",
        "\n",
        "Vi bruker ofte begrepet \"storage bucket\" for en logisk oppdeling av et filomr√•de, tilsvarende som en filmappe p√• din maskin.\n",
        "\n",
        "Data i en storage bucket er som regel ikke klargjort for analyseform√•l. Vi √∏nsker derfor √• prosessere og flytte den til et annet verkt√∏y. Et slikt verkt√∏y kan v√¶re Google BigQuery, som er en database tilpasset analyse. Dette kan videre kobles opp mot visualiserings- og modelleringsverkt√∏y som Colab-notebooks.\n",
        "\n",
        "## Google BigQuery\n",
        "\n",
        "BigQuery er en SQL-basert database som er optimalisert for analyse. I motsetning til tradisjonelle SQL-databaser er BigQuery kolonnebasert istedenfor radbasert. Dette gj√∏r den optimalisert til √• regne ut aggregerte tall. BigQuery takler tabeller med et h√∏yt antall kolonner sv√¶rt godt."
      ],
      "metadata": {
        "id": "DPfwNsUoPddk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# **Bolk 1: Bli kjent med datasettene**\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "wQ3gSFzt9Dnz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Oppgave 1: Bli kjent med Google Cloud Storage** ‚òÅÔ∏è\n",
        "\n",
        "G√• til [Google Cloud Console](https://console.cloud.google.com), logg inn med e-posten din og velg prosjekt \"data-intro\" oppe i venstre hj√∏rne.\n",
        "\n",
        "I Google Cloud Console (GUI) for prosjektet (data-intro), finn Google Cloud Storage. Du kan enten finne GCS via menyen eller s√∏ke etter den i s√∏kefeltet.\n",
        "\n",
        "I prosjektet finner du en bucket med to ulike datasett. Vi skal inspisere metadataen til disse filene.\n",
        "\n",
        "a) Hvilken filtype er de?\n",
        "  \n",
        "  \n",
        "b) Hvor store er filene?\n",
        "  "
      ],
      "metadata": {
        "id": "ydTsudgDBZMF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO\n",
        "# Svar a: csv\n",
        "# Svar b: 1GB"
      ],
      "metadata": {
        "id": "jTiSwTo9_ffb"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Oppgave 2: Importer dataen til BigQuery** üîê\n",
        "\n",
        "For √• se n√¶rmere p√• innholdet i datasettene √∏nsker vi √• flytte de til BigQuery. Gj√∏r f√∏lgende i [Google Cloud Console](https://console.cloud.google.com):\n",
        "\n",
        "1. Finn BigQuery i menyen\n",
        "2. Velg BigQuery-prosjektet \"Data intro\" og deretter marker datasettet bysykkel_main\n",
        "3. I menylinjen oppe til h√∏yre, velg \"Create table\".\n",
        "4. Under \"Source\" kan du velge datakilden din. Vi √∏nsker √• velge bysykkeldatasettet fra Storage Bucket. Filformatet fant du i oppgave 1.\n",
        "5. Under \"Destination\" kan du kalle den nye tabellen din `bysykkel_(gruppenavn)`.\n",
        "6. La BigQuery definere skjema for deg, og behold ellers standard-innstillingene.\n",
        "7. Trykk p√• \"Create Table\"\n",
        "\n",
        "N√• starter en jobb med √• laste inn datasettet fra GCS til BigQuery og vil ta ca. 30 sekunder."
      ],
      "metadata": {
        "id": "9tCc63aZWUgl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Oppgave 3: Bli kjent med bysykkel-datasettet** üö≤\n",
        "\n",
        "N√•r vi markerer tabellen i BigQuery som vi laget i forrige oppgave ser vi en rekke metadata, samt en preview-funksjon for √• unders√∏ke radene i datasettet v√•rt.\n",
        "\n",
        "Hva finner du ut om skjema (datatypene) og innholdet?"
      ],
      "metadata": {
        "id": "be4ImxshDMwB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "## **Oppgave 4: Bli kjent med v√¶rdatasettet** üå¶\n",
        "Vi har allerede lastet inn v√¶rdatasettet inn i BigQuery (`v√¶rdata_oslo`).\n",
        "\n",
        "Hva finner du ut om skjema (datatypene) og innholdet for dette datasettet?\n",
        "\n"
      ],
      "metadata": {
        "id": "cI5dylecWZnY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Bolk 2: Vasking av data**\n",
        "\n",
        "N√• som vi har flyttet datasettene til et passende sted og blitt litt kjent med tabellenes skjema skal vi pr√∏ve √• sl√• disse sammen!"
      ],
      "metadata": {
        "id": "82bhxJ1T8O4S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Autentisering**\n",
        "\n",
        "Det f√∏rste vi m√• gj√∏re er √• autentisere Colab-notebooken mot BigQuery. Koden under vil generere et popup-vindu der du m√• godkjenne dette.\n",
        "\n"
      ],
      "metadata": {
        "id": "s9nSGug2NrRS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Authenticate your Google Account\n",
        "# Doing so means you have access to various\n",
        "# resources connected to your account, such\n",
        "# as BigQuery tables, Storage buckets etc.\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "metadata": {
        "id": "eqEVQIJsT7K1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**BigQuery-klienten**\n",
        "\n",
        "N√• som vi er autentisert, kan vi bruke BigQuery-biblioteket. Kodesnutten under kobler oss til BigQuery-klienten og tar samtidig i bruk `magics`-operatoren som simpelthen lar oss hente data fra en tabell.\n",
        "\n",
        "Kj√∏r kodesnutten under.\n"
      ],
      "metadata": {
        "id": "CSvHGiNTegzl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext google.cloud.bigquery\n",
        "from google.cloud.bigquery import magics\n",
        "magics.context.project = 'data-intro'"
      ],
      "metadata": {
        "id": "oQfp_SWHqeP7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Pandas DataFrames**\n",
        "\n",
        "Operatoren over skriver resultatet fra BigQuery ut som en _DataFrame_ fra Pandas-biblioteket. DataFrames er sv√¶rt nyttige n√•r vi jobber med tabul√¶r data, b√•de for datautforskning og -manipulasjon.\n",
        "\n",
        "Vi kaller dataframesene hhv. `df_bysykkel` og `df_weather`. Kj√∏r kodeblokkene under (husk √• bytte tabell-referanse):"
      ],
      "metadata": {
        "id": "jyJPs0v4T-35"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%bigquery df_bysykkel\n",
        "SELECT * FROM `data-intro.bysykkel_main.bysykkel_august` # Bytt ut med ditt eget tabell-navn\n"
      ],
      "metadata": {
        "id": "N7z9qGJUqvf5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%bigquery df_weather\n",
        "SELECT * FROM `data-intro.bysykkel_main.v√¶rdata_oslo`"
      ],
      "metadata": {
        "id": "jtVUYufOrPge"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Oppgave 5: Lage et utvidet datasett** üë©üèª‚Äçüíª\n",
        "Vi √∏nsker √• sl√• sammen de to datasettene slik at vi kan gj√∏re analyse p√• tvers av disse. F√∏r vi gj√∏r det m√• vi finne en felles kolonne for begge datasett.\n",
        "\n",
        "P√• en DataFrame-instans, `df`, har vi en rekke nyttige metode og felter, f.eks:\n",
        "\n",
        "```python\n",
        "df.shape                  # Dimensjon\n",
        "df.info()                 # Oppsummering av st√∏rrelse og innhold\n",
        "df.describe()             # Grunnleggende statistiske egenskaper\n",
        "df.head()                 # Lister de f√∏rste radene i datasettet\n",
        "df.tail()                 # Lister de siste radene i datasettet\n",
        "df[\"kolonnenavn\"]         # Aksessering av spesifikk kolonne\n",
        "df[\"kolonnenavn\"].iloc[n] # Aksessere rad n i spesifikk kolonne\n",
        "```"
      ],
      "metadata": {
        "id": "AsShu4MB8Ifr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vi m√• finne en kolonne med fellesdata for √• kunne sl√• sammen tabellene. Bruk en (eller flere) av metodene over for √• inspisere innholdet i de to tabellene.  \n",
        "\n",
        "S√• du noen fellesnevnere da du unders√∏kte innholdet i tabellene?"
      ],
      "metadata": {
        "id": "ayDXtr1wJJfv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DITT SVAR HER\n",
        "df_bysykkel['started_at']\n",
        "df_weather['date']"
      ],
      "metadata": {
        "id": "CcnsieJ1Jq0k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Uten √• r√∏pe for mye er det flere gode kolonne-kandidater i `df_bysykkel` som kan brukes p√• √©n kolonne i `df_weather`. Likevel er det ikke mulig √• bruke noen av de rett ut av boksen. Klarer du se hvorfor?\n"
      ],
      "metadata": {
        "id": "Q_TKKnykJtzg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DITT SVAR HER\n",
        "# Ulikt format p√• dato, df_bysykkel er df_weather"
      ],
      "metadata": {
        "id": "I_QBUIIN7vux"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Oppgave 6: Rydde opp i datasettene** üßπ\n",
        "Transformasjoner er en stor og viktig prosess n√•r vi jobber med data. Ofte er datasettene vi har til r√•dighet ikke p√• det formatet vi √∏nsker √• ha de p√•. √Ö transformere data betyr √• gj√∏re endringer, for eksempel:\n",
        "\n",
        "- sl√• sammen datasett\n",
        "- endre p√• datatyper\n",
        "- fjerne duplikater\n",
        "- gj√∏re utregninger med basis i andre kolonner\n",
        "- fjerne potensielle \"outliers\" som kan √∏delegge grunnlaget v√•rt for analyse\n",
        "\n",
        "> Prosessen over kalles ofte for √• \"vaske\" data üßº\n",
        "\n",
        "Vi m√• f√• dato-kolonnene til √• v√¶re p√• samme format. En m√•te vi kan gj√∏re dette p√• er √• fjerne klokkeslettet og kun bruke dato-delen av `started_at`. Ulempen med dette er at vi da mister informasjon vi kanskje √∏nsker √• bruke videre i analysedelen.\n",
        "\n",
        "Vi l√∏ser dette problemet med √• lage en hjelpekolonne, alts√• en ny midlertidg kolonne som kun brukes n√•r vi sl√•r sammen datasettene\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "wJB6gAMbwtfw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Oppgave 6.1**\n",
        "\n",
        "Lag en ny kolonne i `df_bysykkel`, `trip_date`, som kun inneholder datoen fra kolonnen `started_at`. Det kan ta litt tid √• oppdatere de 5.7 millioner radene vi har i tabellen.\n",
        "\n",
        "> **Hint**: Pandas har en funksjon [`to_datetime`](https://pandas.pydata.org/docs/reference/api/pandas.to_datetime.html) som lar deg tilpasse tidspunkter, samt en funksjon [`dt.strftime`](https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.strftime.html) som lar deg formatere dato til et √∏nsket format üêº"
      ],
      "metadata": {
        "id": "aGGRSWyCBUtD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "# DIN KODE HER\n",
        "df_bysykkel['trip_date'] = pd.to_datetime(df_bysykkel['started_at']).dt.strftime['%Y-%m-%d']\n",
        "df_bysykkel.head()\n",
        "print(df_bysykkel.head())"
      ],
      "metadata": {
        "id": "8YSrupR_w0x3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title L√∏sningsforslag\n",
        "import pandas as pd\n",
        "df_bysykkel[\"trip_date\"] = pd.to_datetime(df_bysykkel[\"started_at\"]).dt.strftime(\"%Y-%m-%d\")\n",
        "df_bysykkel.head()"
      ],
      "metadata": {
        "id": "nS7wQ0nz9qnW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Oppgave 6.2**\n",
        "Fors√∏k √• sl√• sammen de to datasettene med hjelpekolonnen `trip_date` ved √• bruke Pandas' [merge](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.merge.html)-funksjon. Fungerer det √• sl√• sammen n√•? Hvordan ser datasettet ut?\n",
        "\n",
        "> **Hint:** Du kan sjekke hvilke datatyper dataframen din inneholder ved √• bruke Pandas sitt `dtypes`-attributt, f.eks `df_bysykkel.dtypes`"
      ],
      "metadata": {
        "id": "fnxmSPiGN4b9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DIN KODE HER\n",
        "df_merged = df_bysykkel.merge(df_weather, how='outer', left_on='trip_date', right_on='date')"
      ],
      "metadata": {
        "id": "O1AaLoZ9NzjD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "outputId": "d48af1ee-6e1a-401f-a701-498cf41d780a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-8a12da829080>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# DIN KODE HER\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf_merged\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_bysykkel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_merged\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df_bysykkel' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title L√∏sningsforslag\n",
        "\"\"\"\n",
        "Det vil i prinsippet fungere, men det er likevel ikke riktig fordi kolonnene har\n",
        "ulike datatyper - started_at er av typen datetime64 og trip_date er av typen object\n",
        "\"\"\""
      ],
      "metadata": {
        "cellView": "form",
        "id": "yuGEPmx2opXQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "a77dee3c-252b-4cf3-8c9c-5f41833f0593"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nDet vil i prinsippet fungere, men det er likevel ikke riktig fordi kolonnene har\\nulike datatyper - started_at er av typen datetime64 og trip_date er av typen object\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Oppgave 6.3**\n",
        "Gj√∏r n√∏dvendige endringer i kolonnen `trip_date` i bysykkeldatasettet og `date` i v√¶rdatasettet for √• kunne sl√• sammen.\n"
      ],
      "metadata": {
        "id": "E-QdbA1COWN_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DIN KODE HER\n",
        "import pandas as pd\n",
        "\n",
        "df_bysykkel['trip_date'] = pd.to_datetime(df_bysykkel['trip_date'])\n",
        "df_weather['date'] = pd.to_datetime(weather['date'])"
      ],
      "metadata": {
        "id": "lR-0dx0cxB6_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title L√∏sningsforslag\n",
        "\n",
        "# Vi setter begge kolonnen til √• v√¶re av type datetime (datotid).\n",
        "\n",
        "df_bysykkel[\"trip_date\"] = pd.to_datetime(df_bysykkel[\"trip_date\"])\n",
        "df_weather[\"date\"] = pd.to_datetime(df_weather[\"date\"])"
      ],
      "metadata": {
        "id": "wUGlrEsUu8uM",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Oppgave 6.4**\n",
        "N√• skal det fungere √• sl√• sammen datasettene! üéâ Vi √∏nsker √• supplere hver rad av bysykkeldatasettet med v√¶rdata fra den aktuelle dagen. Skriv kode under som oppn√•r dette.\n",
        "\n",
        "> üí° Rekkef√∏lgen og type join (left, right, outer etc.) har noe √• si n√•r datasettene sl√•s sammen. Tommelfingerregelen er at man alltid skal starte med den st√∏rste tabellen ved en merge av ytelsesgrunner. Forskjellen p√• type joins kan man lese mer om [her](https://stackoverflow.com/questions/5706437/whats-the-difference-between-inner-join-left-join-right-join-and-full-join).\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "vy9wVOCGyB_-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DIN KODE HER\n"
      ],
      "metadata": {
        "id": "30ZZiRcWyGdK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title L√∏sningsforslag\n",
        "df_merged = df_bysykkel.merge(df_weather, left_on=\"trip_date\", right_on=\"date\", how=\"left\")\n",
        "df_merged.head()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "XFT0gIqkv9ej"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Oppgave 6.5**\n",
        "Om vi sjekker typene til kolonnene med v√¶rdata (ved bruk av `df_merged.dtypes` igjen) ser vi at verdiene i disse kolonnene er strenger. Det gj√∏r det ikke mulig for oss √• aggregere verdiene, s√• vi er n√∏dt til √• f√• de over p√• tallformat.\n",
        "\n",
        "Kodesnutten under fors√∏ker √• gj√∏re om verdiene p√• temperatur og nedb√∏rsmengde til typen `float`. Hvorfor fungerer det ikke √• gj√∏re om kolonnen direkte?"
      ],
      "metadata": {
        "id": "vPrY9Nj9yLdm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_merged[\"mean_temperature\"] = df_merged[\"mean_temperature\"].astype('float')\n",
        "df_merged[\"precipitation_amount\"] = df_merged[\"precipitation_amount\"].astype('float')"
      ],
      "metadata": {
        "id": "Y6lQfo3LUYn0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title L√∏sningsforslag\n",
        "\"\"\"\n",
        "Kolonnen ser tilsynelatende ut til √• kun best√• av tall. Hvis vi derimot inspiserer\n",
        "verdiene n√¶rmere, ser vi at noen ganger forekommer strengen \"NULL\" som ikke er et tall.\n",
        "Pandas f√•r derfor ikke til √• gj√∏re om datatypen f√∏r vi gj√∏r noe med dette.\n",
        "\"\"\""
      ],
      "metadata": {
        "cellView": "form",
        "id": "XS7ylVVnzD0h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Oppgave 6.6**\n",
        "Endre datatypen p√• nedb√∏rskolonnen og temperaturkolonnen slik at det blir desimaltall.\n",
        "\n",
        "> **Hint**: Vi er n√∏dt til √• fjerne `NULL`-verdiene vi oppdaget i forrige oppgave. Bruk `replace`-funksjonen til dette ved √• sette en tom verdi, som i Python-verdenen heter `None`. Kan du tenke deg hvorfor vi bruker en tom verdi istedenfor eksempelvis 0 her?"
      ],
      "metadata": {
        "id": "4sbgPwHLZgvJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DIN KODE HER"
      ],
      "metadata": {
        "id": "m0GmJP7GYv9b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title L√∏sningsforslag\n",
        "df_merged[\"mean_temperature\"] = df_merged[\"mean_temperature\"].replace({'NULL': None}).astype('float')\n",
        "df_merged[\"precipitation_amount\"] = df_merged[\"precipitation_amount\"].replace({'NULL': None}).astype('float')\n",
        "\n",
        "\"\"\"\n",
        "Vi kunne teknisk sett gjort om NULL til 0, men dette ville f√•tt betydning for\n",
        "statistiske verdier som gjennomsnitt og lignende. Hvordan man h√•ndterer NULL-verdier\n",
        "avhenger av bruksomr√•det og krever ofte dypere forst√•else av domenet man jobber med.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "JDrCEgmS0wef",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Oppgave 6.7**\n",
        "\n",
        "Rydd opp ved √• fjerne hjelpekolonnen fra `df_merged`\n",
        "\n",
        "> **Hint**: `drop`-funksjonen kan komme godt med her üóë\n"
      ],
      "metadata": {
        "id": "sk8NH-K9Uo6-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DIN KODE HER"
      ],
      "metadata": {
        "id": "GpdDnOQoyPbq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title L√∏sningsforslag\n",
        "df_merged = df_merged.drop(columns=\"trip_date\")\n",
        "df_merged.head()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "g_bJiQPB10vb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Vi har n√• et utvidet datasett! üéâü•Çüéä\n",
        "\n",
        "\n",
        "Vanligvis ville vi ha skrevet datasettet tilbake til BigQuery, men det gj√∏r vi ikke i denne workshopen (det tar lang tid, vi har mye dataüò¥)\n",
        "\n",
        "Pandas har en ganske snedig funksjon som kan gj√∏re dette!\n",
        "\n",
        "```df_merged.to_gbq(\"bysykkel_main.bysykkel_med_v√¶rdata\", project_id=\"data-intro\")```\n",
        "\n",
        "N√•r vi skriver til BigQuery, vil datatypene i dataframen f√∏lge med og sette riktig skjema i BigQuery\n"
      ],
      "metadata": {
        "id": "vUZMf3ycUY7D"
      }
    }
  ]
}